{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_nn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNW5EXghNzr/FHg74r8PZXq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pen1064/Practice/blob/main/pytorch_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ovckKv2ZeR0e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "from torch import nn\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHES = 10\n",
        "BATCHSIZE = 64"
      ],
      "metadata": {
        "id": "G7xw8w5FiMz8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "5MgZ3i6VfraW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inFeatures = 4 #4D vector for each observation\n",
        "hiddenDim = 8\n",
        "nbClasses = 3\n",
        "model = torch.nn.Sequential(nn.Linear(inFeatures, hiddenDim), \n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(hiddenDim, nbClasses))"
      ],
      "metadata": {
        "id": "MvNoYvfXgwwE"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_batches(XX, yy, batchSize):\n",
        "  for i in range(0, XX.shape[0],batchSize):\n",
        "    yield(XX[i:i+batchSize], yy[i:i+batchSize])"
      ],
      "metadata": {
        "id": "M4W_kK69FiUD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X, y) = make_blobs(n_samples=1000, n_features=4, centers=3,cluster_std=2.5, random_state=95)\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.8, random_state=22)"
      ],
      "metadata": {
        "id": "LY75k835eT-V"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to tensor\n",
        "Xtrain = torch.from_numpy(Xtrain).float()\n",
        "ytrain = torch.from_numpy(ytrain).long()\n",
        "Xtest = torch.from_numpy(Xtest).float()\n",
        "ytest = torch.from_numpy(ytest).long()"
      ],
      "metadata": {
        "id": "f0QT_HtriJ8c"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put the model to device\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "AsYBMQgeH83L"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-2\n",
        "opt = torch.optim.SGD(model.parameters(), lr = lr)\n",
        "lossfn = nn.CrossEntropyLoss()\n",
        "Train_Losses = []\n",
        "Train_Accuracies = []\n",
        "for epoch in range(EPOCHES):\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  num_sample = 0\n",
        "  model.train()\n",
        "  for (xbatch, ybatch) in create_batches(Xtrain, ytrain, BATCHSIZE):\n",
        "    (xbatch, ybatch) = (xbatch.to(device), ybatch.to(device))\n",
        "    y_pred = model(xbatch)\n",
        "    loss = lossfn(y_pred, ybatch)\n",
        "\n",
        "    opt.zero_grad() #zero the gradient\n",
        "    loss.backward() #calculate gradient and stuff\n",
        "    opt.step() #update the weight\n",
        "\n",
        "    train_loss += loss.item()*ybatch.size(0)\n",
        "    train_acc += (y_pred.max(1)[1] == ybatch).sum().item()\n",
        "    num_sample += ybatch.size(0)\n",
        "    \n",
        "  Train_Losses.append(train_loss)\n",
        "  Train_Accuracies.append(train_acc)\n",
        "  trainTemplate = \"epoch: {} train loss: {:.3f} train accuracy: {:.3f}\"\n",
        "  print(trainTemplate.format(epoch, train_loss/num_sample, train_acc/num_sample))\n",
        "\n",
        "  # Test after each epoch\n",
        "  model.eval()\n",
        "  test_acc = 0\n",
        "  test_loss = 0\n",
        "  test_num_sample = 0\n",
        "  with torch.no_grad():\n",
        "    for (Xtest_batch, ytest_batch) in create_batches(Xtest, ytest, BATCHSIZE):\n",
        "      Xtest_batch, ytest_batch = Xtest_batch.to(device), ytest_batch.to(device)\n",
        "      ytest_pred = model(Xtest_batch)\n",
        "      test_loss = lossfn(ytest_pred, ytest_batch)\n",
        "\n",
        "      test_acc += (ytest_pred.max(1)[1] == ytest_batch).sum().item()\n",
        "      test_loss += test_loss.item()*ytest_batch.size(0)\n",
        "      test_num_sample += ytest_batch.size(0)\n",
        "    testTemplate = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
        "    print(testTemplate.format(epoch, test_loss/test_num_sample, test_acc/test_num_sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_RQE8bag13f",
        "outputId": "5f8b07a8-bdae-4631-a712-2ee3c828c62b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 train loss: 0.046 train accuracy: 0.990\n",
            "epoch: 0 test loss: 0.001 test accuracy: 0.995\n",
            "epoch: 1 train loss: 0.046 train accuracy: 0.990\n",
            "epoch: 1 test loss: 0.001 test accuracy: 0.995\n",
            "epoch: 2 train loss: 0.046 train accuracy: 0.990\n",
            "epoch: 2 test loss: 0.001 test accuracy: 0.995\n",
            "epoch: 3 train loss: 0.046 train accuracy: 0.990\n",
            "epoch: 3 test loss: 0.001 test accuracy: 0.995\n",
            "epoch: 4 train loss: 0.045 train accuracy: 0.990\n",
            "epoch: 4 test loss: 0.001 test accuracy: 0.995\n",
            "epoch: 5 train loss: 0.045 train accuracy: 0.990\n",
            "epoch: 5 test loss: 0.001 test accuracy: 0.995\n",
            "epoch: 6 train loss: 0.045 train accuracy: 0.990\n",
            "epoch: 6 test loss: 0.000 test accuracy: 0.995\n",
            "epoch: 7 train loss: 0.045 train accuracy: 0.990\n",
            "epoch: 7 test loss: 0.000 test accuracy: 0.995\n",
            "epoch: 8 train loss: 0.045 train accuracy: 0.990\n",
            "epoch: 8 test loss: 0.000 test accuracy: 0.995\n",
            "epoch: 9 train loss: 0.045 train accuracy: 0.990\n",
            "epoch: 9 test loss: 0.000 test accuracy: 0.995\n"
          ]
        }
      ]
    }
  ]
}